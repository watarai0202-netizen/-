import os
from datetime import datetime, timedelta, timezone

import streamlit as st

from src.tdnet import fetch_tdnet_items
from src.analyzer import analyze_pdf_to_json, ai_is_enabled
from src.storage import init_db, get_cached_analysis, save_analysis, db_path_default
from src.viz import render_analysis

# ----------------------------
# Page
# ----------------------------
st.set_page_config(page_title="æ±ºç®—çŸ­ä¿¡ã‚¹ã‚¯ãƒªãƒ¼ãƒŠãƒ¼", layout="wide")

# ----------------------------
# Auth (simple password gate)
# ----------------------------
APP_PASSWORD = st.secrets.get("APP_PASSWORD", "")
if not APP_PASSWORD:
    st.error("APP_PASSWORD ãŒæœªè¨­å®šã§ã™ï¼ˆSecretsã«è¨­å®šã—ã¦ãã ã•ã„ï¼‰")
    st.stop()

if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

if not st.session_state.authenticated:
    st.title("èªè¨¼ãŒå¿…è¦ã§ã™")
    pw = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
    if pw == APP_PASSWORD:
        st.session_state.authenticated = True
        st.rerun()
    st.stop()

# ----------------------------
# DB init (cache store)
# ----------------------------
DB_PATH = st.secrets.get("DB_PATH", db_path_default())
init_db(DB_PATH)

# ----------------------------
# Header
# ----------------------------
st.title("ğŸ“ˆ æ±ºç®—çŸ­ä¿¡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° & ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚º")
st.caption("ç‹™ã„ï¼šã‚¹ãƒãƒ›ã§ã‚‚ã€ŒéŠ˜æŸ„â†’æ±ºç®—â†’è¦ç‚¹ï¼‹æ•°å€¤ã€ã¾ã§æœ€çŸ­ã§è¦‹ã‚‹ã€‚AIè¦ç´„ã¯æŠ¼ã—ãŸæ™‚ã ã‘å®Ÿè¡Œã€‚")

# ----------------------------
# Screening controls
# ----------------------------
with st.expander("ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¡ä»¶", expanded=True):
    col1, col2, col3 = st.columns([2, 2, 2])

    with col1:
        code = st.text_input("éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ï¼ˆ4æ¡ã€ç©ºãªã‚‰ç›´è¿‘å…¨ä½“ï¼‰", value="").strip()
        only_kessan = st.checkbox("æ±ºç®—çŸ­ä¿¡ã ã‘ã«çµã‚‹", value=True)

    with col2:
        days = st.slider("ç›´è¿‘ä½•æ—¥ã‚’è¦‹ã‚‹ï¼Ÿ", 1, 14, 3)
        limit = st.slider("å–å¾—ä»¶æ•°ï¼ˆå¤§ãã„ã»ã©é…ã„ï¼‰", 50, 500, 200)

    with col3:
        only_has_doc_url = st.checkbox("PDF URLãŒã‚ã‚‹ã‚‚ã®ã ã‘", value=True)
        show_ai_button = st.checkbox("AIåˆ†æãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º", value=True)

# sanity for code
if code and (not code.isdigit() or len(code) != 4):
    st.warning("éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã¯4æ¡ã®æ•°å­—ã§å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼š7203ï¼‰")
    code = ""

# ----------------------------
# Fetch TDnet index (non-scrape)
# ----------------------------
cutoff_utc = datetime.now(timezone.utc) - timedelta(days=days)
with st.spinner("é–‹ç¤ºä¸€è¦§ã‚’å–å¾—ä¸­..."):
    items = fetch_tdnet_items(code or None, limit=limit)

# Filter
filtered = []
for it in items:
    title = (it.get("title") or "").strip()
    doc_url = (it.get("doc_url") or "").strip()
    published = it.get("published_at")

    if only_kessan and "æ±ºç®—çŸ­ä¿¡" not in title:
        continue
    if only_has_doc_url and not doc_url:
        continue
    if published and published < cutoff_utc:
        continue

    filtered.append(it)

st.subheader(f"å€™è£œï¼š{len(filtered)}ä»¶")
if not filtered:
    st.info("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹é–‹ç¤ºãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ—¥æ•°ã‚„ä»¶æ•°ã‚’åºƒã’ã¦ãã ã•ã„ã€‚")
    st.stop()

# AI availability
ai_ok = ai_is_enabled()
if show_ai_button and not ai_ok:
    st.warning("Gemini APIã‚­ãƒ¼æœªè¨­å®šã®ãŸã‚ã€AIåˆ†æã¯ç„¡åŠ¹ã§ã™ï¼ˆæ•°å€¤è¡¨ç¤ºã®ã¿ï¼‰ã€‚Secretsã« GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")

# ----------------------------
# Render list
# ----------------------------
# ã‚¹ãƒãƒ›å‰æï¼š1ä»¶ãšã¤expanderã§é–‹ã UI
for it in filtered[:100]:
    title = it.get("title", "")
    code_ = it.get("code", "")
    doc_url = it.get("doc_url", "")
    published = it.get("published_at")
    published_str = published.astimezone(timezone.utc).strftime("%Y-%m-%d %H:%M UTC") if published else "ä¸æ˜"

    label = f"{code_}ï½œ{published_str}ï½œ{title}"
    with st.expander(label, expanded=False):
        st.caption(f"PDF: {doc_url}")

        cached = get_cached_analysis(DB_PATH, doc_url) if doc_url else None
        if cached:
            st.success("è§£ææ¸ˆã¿ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰")
            render_analysis(cached)
        else:
            st.info("æœªè§£æ")

        cols = st.columns([1, 1, 2])
        with cols[0]:
            if st.button("ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¡¨ç¤º", key=f"show_{doc_url}") and cached:
                render_analysis(cached)
        with cols[1]:
            can_run_ai = show_ai_button and ai_ok and bool(doc_url)
            run = st.button("AIåˆ†æ", key=f"ai_{doc_url}", disabled=not can_run_ai)
        with cols[2]:
            st.caption("â€»åŒã˜PDF URLã¯SQLiteã«ä¿å­˜ã—ã€å†è§£æã—ã¾ã›ã‚“ï¼ˆDBã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ‰±ã„ï¼‰ã€‚")

        if run:
            with st.spinner("AIãŒæ±ºç®—çŸ­ä¿¡ã‚’è§£æä¸­..."):
                try:
                    payload = analyze_pdf_to_json(doc_url)
                    save_analysis(DB_PATH, doc_url, code_, title, published, payload)
                    st.success("è§£æå®Œäº†")
                    render_analysis(payload)
                except Exception as e:
                    st.error(f"è§£æã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")

st.divider()

# Manual analyze
st.subheader("æ‰‹å‹•è§£æï¼ˆPDF URLã‚’è²¼ã‚‹ï¼‰")
manual = st.text_input("PDF URLï¼ˆ.pdfæ¨å¥¨ï¼‰", value="").strip()
colA, colB = st.columns([1, 3])
with colA:
    manual_run = st.button("AIè§£æ", disabled=not (ai_ok and manual))
with colB:
    st.caption("â€»PDFä»¥å¤–ã®URLã ã¨å¤±æ•—ã—ã¾ã™ï¼ˆHTMLãªã©ï¼‰ã€‚")

if manual_run:
    with st.spinner("AIãŒè§£æä¸­..."):
        payload = analyze_pdf_to_json(manual)
    st.json(payload)
